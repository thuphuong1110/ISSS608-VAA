{
  "hash": "6d7d2f79ff8f27d58688fa29153c213d",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Hands-on Exercise 4.2: Visual Statistical Analysis\"\nauthor: \"Nguyen Bao Thu Phuong\"\ndate: \"23 January 2025\" \ndate-modified: \"last-modified\"\nexecute:\n  eval: true\n  echo: true\n  message: false\n  freeze: true\n  warning: false\n---\n\n\n\n# Overview\n\nThis hands-on exercise provides practical experience in using the following R packages:\n\n-   ggstatsplot: To create visually rich statistical graphics.\n\n-   performance: To visualize model diagnostics and assess model performance.\n\n-   parameters: To visualize model parameters and their uncertainties.\n\n# Visual Statistical Analysis with ggstatsplot\n\n**ggstatsplot** is an extension package for **ggplot2** that specializes in creating information-rich plots that incorporate statistical test details directly within the visualization. It offers 2 key functionalities:\n\n-   Alternative Statistical Methods: By default, `ggstatsplot` provides alternative statistical inference methods compared to base `ggplot2`.\n\n-   Best Practices in Reporting: The package adheres to the APA (American Psychological Association) style guide, considered a gold standard for statistical reporting. This ensures plots generated by `ggstatsplot` follow best practices in presenting statistical test results.\n\n![](data/image22.jpg)\n\n# Getting Started\n\n## Installing and launching R packages\n\nThe below code chunk loads **ggstatsplot** and **tidyverse** into R environment.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npacman::p_load(ggstatsplot, tidyverse)\n```\n:::\n\n\n\n## Importing data\n\nThe code chunk below uses `read_csv()`of [**readr**](#0) package to import *Exam_data.csv* into R and saved it into a tibble data.frame.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nexam <- read_csv(\"data/Exam_data.csv\")\nexam\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 322 × 7\n   ID         CLASS GENDER RACE    ENGLISH MATHS SCIENCE\n   <chr>      <chr> <chr>  <chr>     <dbl> <dbl>   <dbl>\n 1 Student321 3I    Male   Malay        21     9      15\n 2 Student305 3I    Female Malay        24    22      16\n 3 Student289 3H    Male   Chinese      26    16      16\n 4 Student227 3F    Male   Chinese      27    77      31\n 5 Student318 3I    Male   Malay        27    11      25\n 6 Student306 3I    Female Malay        31    16      16\n 7 Student313 3I    Male   Chinese      31    21      25\n 8 Student316 3I    Male   Malay        31    18      27\n 9 Student312 3I    Male   Malay        33    19      15\n10 Student297 3H    Male   Indian       34    49      37\n# ℹ 312 more rows\n```\n\n\n:::\n:::\n\n\n\n## One-sample test: *gghistostats()* method\n\nThe code chunk below uses [*gghistostats()*](https://indrajeetpatil.github.io/ggstatsplot/reference/gghistostats.html) to build a visual of one-sample test on English scores.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1234)\n\ngghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"bayes\",\n  test.value = 60,\n  xlab = \"English scores\"\n)\n```\n\n::: {.cell-output-display}\n![](Hands-on_Ex042_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n\nDefault information from above graph:\n\n-   Statistical details\n\n-   Bayes Factor\n\n-   Sample sizes\n\n-   Distribution summary\n\n## Unpacking the Bayes Factor\n\nThe Bayes factor is a crucial concept in Bayesian statistics. It quantifies the strength of evidence in favor of one hypothesis (H1, the alternative hypothesis) compared to another (H0, the null hypothesis). This ratio allows for the evaluation of data in the context of both the null hypothesis and prior beliefs or external information. When comparing H1 and H0, the Bayes factor is typically denoted as B10 and defined mathematically as.\n\n![](data/image5.jpg)\n\nThe [**Schwarz criterion**](https://www.statisticshowto.com/bayesian-information-criterion/) provides a relatively straightforward method for approximating the Bayes factor.\n\n## How to interpret Bayes Factor\n\nA **Bayes Factor** can be any positive number. One of the most common interpretations first proposed by Harold Jeffereys (1961) and slightly modified by [Lee and Wagenmakers](#0) in 2013.\n\n![](data/image6.jpg)\n\n## Two-sample mean test: *ggbetweenstats()*\n\nThe code chunk below use [*ggbetweenstats()*](https://indrajeetpatil.github.io/ggstatsplot/reference/ggbetweenstats.html) to build a visual for two-sample mean test of Maths scores by gender.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggbetweenstats(\n  data = exam,\n  x = GENDER, \n  y = MATHS,\n  type = \"np\",\n  messages = FALSE\n)\n```\n\n::: {.cell-output-display}\n![](Hands-on_Ex042_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n\nDefault information: statistical details, Bayes Factor, sample sizes, distribution summary\n\n## Oneway ANOVA Test: *ggbetweenstats()* method\n\nThe code chunk below uses [*ggbetweenstats()*](https://indrajeetpatil.github.io/ggstatsplot/reference/ggbetweenstats.html) to build a visual for One-way ANOVA test on English score by race.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggbetweenstats(\n  data = exam,\n  x = RACE, \n  y = ENGLISH,\n  type = \"p\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n```\n\n::: {.cell-output-display}\n![](Hands-on_Ex042_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n\n-   “ns” → only non-significant\n\n-   “s” → only significant\n\n-   “all” → everything\n\n### ggbetweenstats - Summary of tests\n\n![](data/image7.jpg)\n\n![](data/image8.jpg)\n\n![](data/image9.jpg)\n\n## Significant Test of Correlation: *ggscatterstats()*\n\nThe code chunk below uses [*ggscatterstats()*](https://indrajeetpatil.github.io/ggstatsplot/reference/ggscatterstats.html) to build a visual for Significant Test of Correlation between Maths scores and English scores.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggscatterstats(\n  data = exam,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = FALSE,\n  )\n```\n\n::: {.cell-output-display}\n![](Hands-on_Ex042_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n\n## Significant Test of Association (Depedence) : *ggbarstats()* methods\n\nThe code chunk below bins the Maths scores into a 4-class variable using [*cut()*](https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/cut).\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nexam1 <- exam %>% \n  mutate(MATHS_bins = \n           cut(MATHS, \n               breaks = c(0,60,75,85,100))\n)\n```\n:::\n\n\n\nNext we use [*ggbarstats()*](https://indrajeetpatil.github.io/ggstatsplot/reference/ggbarstats.html) to build a visual for Significant Test of Association.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggbarstats(exam1, \n           x = MATHS_bins, \n           y = GENDER)\n```\n\n::: {.cell-output-display}\n![](Hands-on_Ex042_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\n\n# Visualising Models\n\nThis section focuses on leveraging the `parameters` package to visualize model diagnostics and parameters. We will utilize the Toyota Corolla case study as an example, where the objective is to build a model that predicts used-car prices based on a set of explanatory variables.\n\n# Getting Started\n\n## Installing and loading the required libraries\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npacman::p_load(readxl, performance, parameters, see)\n```\n:::\n\n\n\n## Importing Excel file: readxls methods\n\nIn the code chunk below, [*read_xls()*](https://readxl.tidyverse.org/reference/read_excel.html) of [**readxl**](https://readxl.tidyverse.org/) package is used to import the data worksheet of `ToyotaCorolla.xls` workbook into R.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncar_resale <- read_xls(\"data/ToyotaCorolla.xls\", \n                       \"data\")\ncar_resale\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1,436 × 38\n      Id Model          Price Age_08_04 Mfg_Month Mfg_Year    KM Fuel_Type    HP\n   <dbl> <chr>          <dbl>     <dbl>     <dbl>    <dbl> <dbl> <chr>     <dbl>\n 1     1 TOYOTA Coroll… 13500        23        10     2002 46986 Diesel       90\n 2     2 TOYOTA Coroll… 13750        23        10     2002 72937 Diesel       90\n 3     3  TOYOTA Corol… 13950        24         9     2002 41711 Diesel       90\n 4     4 TOYOTA Coroll… 14950        26         7     2002 48000 Diesel       90\n 5     5 TOYOTA Coroll… 13750        30         3     2002 38500 Diesel       90\n 6     6 TOYOTA Coroll… 12950        32         1     2002 61000 Diesel       90\n 7     7  TOYOTA Corol… 16900        27         6     2002 94612 Diesel       90\n 8     8 TOYOTA Coroll… 18600        30         3     2002 75889 Diesel       90\n 9     9  TOYOTA Corol… 21500        27         6     2002 19700 Petrol      192\n10    10  TOYOTA Corol… 12950        23        10     2002 71138 Diesel       69\n# ℹ 1,426 more rows\n# ℹ 29 more variables: Met_Color <dbl>, Color <chr>, Automatic <dbl>, CC <dbl>,\n#   Doors <dbl>, Cylinders <dbl>, Gears <dbl>, Quarterly_Tax <dbl>,\n#   Weight <dbl>, Mfr_Guarantee <dbl>, BOVAG_Guarantee <dbl>,\n#   Guarantee_Period <dbl>, ABS <dbl>, Airbag_1 <dbl>, Airbag_2 <dbl>,\n#   Airco <dbl>, Automatic_airco <dbl>, Boardcomputer <dbl>, CD_Player <dbl>,\n#   Central_Lock <dbl>, Powered_Windows <dbl>, Power_Steering <dbl>, …\n```\n\n\n:::\n:::\n\n\n\nNote that the output object `car_resale` is a tibble data frame.\n\n## Multiple Regression Model using lm()\n\nThe code chunk below calibrates a multiple linear regression model using *lm()* of Base Stats of R.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel <- lm(Price ~ Age_08_04 + Mfg_Year + KM + \n              Weight + Guarantee_Period, data = car_resale)\nmodel\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = Price ~ Age_08_04 + Mfg_Year + KM + Weight + Guarantee_Period, \n    data = car_resale)\n\nCoefficients:\n     (Intercept)         Age_08_04          Mfg_Year                KM  \n      -2.637e+06        -1.409e+01         1.315e+03        -2.323e-02  \n          Weight  Guarantee_Period  \n       1.903e+01         2.770e+01  \n```\n\n\n:::\n:::\n\n\n\n## Model Diagnostic: checking for multicollinearity\n\nThe code chunk below uses [*check_collinearity()*](https://easystats.github.io/performance/reference/check_collinearity.html) of [**performance**](https://easystats.github.io/performance/index.html) package to calculate multicollinearity of the derived model.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncheck_collinearity(model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Check for Multicollinearity\n\nLow Correlation\n\n             Term  VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n               KM 1.46 [ 1.37,  1.57]         1.21      0.68     [0.64, 0.73]\n           Weight 1.41 [ 1.32,  1.51]         1.19      0.71     [0.66, 0.76]\n Guarantee_Period 1.04 [ 1.01,  1.17]         1.02      0.97     [0.86, 0.99]\n\nHigh Correlation\n\n      Term   VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n Age_08_04 31.07 [28.08, 34.38]         5.57      0.03     [0.03, 0.04]\n  Mfg_Year 31.16 [28.16, 34.48]         5.58      0.03     [0.03, 0.04]\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncheck_c <- check_collinearity(model)\nplot(check_c)\n```\n\n::: {.cell-output-display}\n![](Hands-on_Ex042_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\n\n## Model Diagnostic: checking normality assumption\n\nThe code chunk below uses [*check_collinearity()*](https://easystats.github.io/performance/reference/check_collinearity.html) of [**performance**](https://easystats.github.io/performance/index.html) package to calculate multicollinearity of the derived model.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel1 <- lm(Price ~ Age_08_04 + KM + \n              Weight + Guarantee_Period, data = car_resale)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncheck_n <- check_normality(model1)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(check_n)\n```\n\n::: {.cell-output-display}\n![](Hands-on_Ex042_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\n\n## Model Diagnostic: Check model for homogeneity of variances\n\nThe code chunk uses [*check_heteroscedasticity()*](https://easystats.github.io/performance/reference/check_heteroscedasticity.html) of [**performance**](https://easystats.github.io/performance/index.html) package.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncheck_h <- check_heteroscedasticity(model1)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(check_h)\n```\n\n::: {.cell-output-display}\n![](Hands-on_Ex042_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n\n\n## Model Diagnostic: Complete check\n\nWe can also perform the complete check using [*check_model()*](https://easystats.github.io/performance/reference/check_model.html).\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncheck_model(model1)\n```\n\n::: {.cell-output-display}\n![](Hands-on_Ex042_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n\n\n## Visualising Regression Parameters: see methods\n\nIn the code below, `plot()` of **see** package and `parameters()` of **parameters** package are used to visualise the parameters of a regression model.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(parameters(model1))\n```\n\n::: {.cell-output-display}\n![](Hands-on_Ex042_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n\n\n## Visualising Regression Parameters: *ggcoefstats()* methods\n\nThe code below uses [*ggcoefstats()*](https://indrajeetpatil.github.io/ggstatsplot/reference/ggcoefstats.html) of **ggstatsplot** package to visualise the parameters of a regression model.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggcoefstats(model1, \n            output = \"plot\")\n```\n\n::: {.cell-output-display}\n![](Hands-on_Ex042_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n:::\n",
    "supporting": [
      "Hands-on_Ex042_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}